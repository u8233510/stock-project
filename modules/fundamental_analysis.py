import streamlit as st
import pandas as pd
import database
import requests
from duckduckgo_search import DDGS


def _build_fundamental_prompt(stock_name, sid, search_ctx, metrics):
    """å»ºç«‹å›ºå®šç« ç¯€æ ¼å¼çš„åŸºæœ¬é¢åˆ†æ Promptã€‚"""
    return f"""
è«‹ä½ æ‰®æ¼”å°è‚¡è³‡æ·±åŸºæœ¬é¢åˆ†æå¸«ï¼Œé‡å° {stock_name}ï¼ˆ{sid}ï¼‰æ’°å¯«å ±å‘Šã€‚

ã€é‡è¦è¦å‰‡ã€‘
1) åš´æ ¼ä½¿ç”¨ä»¥ä¸‹å›ºå®šæ ¼å¼èˆ‡æ¨™é¡Œé †åºï¼Œä¸è¦å¢æ¸›ç« ç¯€ã€‚
2) è‹¥è³‡æ–™ä¸è¶³ï¼Œè«‹æ˜ç¢ºå¯«ã€Œæœªæä¾›ã€æˆ–ã€Œè³‡æ–™ä¸è¶³ã€ï¼Œç¦æ­¢è™›æ§‹ã€‚
3) æ‰€æœ‰æ•¸å€¼ç›¡é‡å¼•ç”¨æˆ‘æä¾›çš„è³‡æ–™ï¼›è‹¥å¼•ç”¨æ–°èï¼Œåƒ…èƒ½ä½¿ç”¨ã€Œæœå°‹äº‹å¯¦æ‘˜è¦ã€ã€‚
4) ä»¥ç¹é«”ä¸­æ–‡è¼¸å‡ºã€‚

ã€å›ºå®šè¼¸å‡ºæ ¼å¼ã€‘
## å…¬å¸ç°¡ä»‹
ï¼ˆå…¬å¸å®šä½ã€æ ¸å¿ƒç”¢å“/æœå‹™ã€ä¸»è¦å¸‚å ´ï¼‰

## è²¡å‹™åˆ†æ
ï¼ˆæ•´é«”ç²åˆ©èƒ½åŠ›èˆ‡è¿‘æ³ï¼Œ2-4 å¥ï¼‰

### è²¡å‹™æŒ‡æ¨™
- EPSï¼š
- ROEï¼ˆè‚¡æ±æ¬Šç›Šå ±é…¬ç‡ï¼‰ï¼š
- ROAï¼ˆè³‡ç”¢å ±é…¬ç‡ï¼‰ï¼š
- ç‡Ÿæ”¶æˆé•·ç‡ï¼š
- æ¯›åˆ©ç‡ï¼š

## ç‡Ÿæ”¶åˆ†æ
ï¼ˆç‡Ÿæ”¶è¶¨å‹¢ã€å¯èƒ½é©…å‹•å› å­ï¼‰

## æ¯›åˆ©ç‡åˆ†æ
ï¼ˆæ¯›åˆ©ç‡æ°´æº–èˆ‡å¯èƒ½åŸå› ï¼›è‹¥ç„¡è³‡æ–™è«‹å¯«æœªæä¾›ï¼‰

## ç¾é‡‘æµé‡åˆ†æ
ï¼ˆç¾é‡‘æµé‡ç‹€æ³èˆ‡å“è³ªï¼›è‹¥ç„¡è³‡æ–™è«‹å¯«æœªæä¾›ï¼‰

## æŠ•è³‡è©•åƒ¹
- çŸ­æœŸè©•åƒ¹ï¼š
- ä¸­æœŸè©•åƒ¹ï¼š
- é•·æœŸè©•åƒ¹ï¼š
- ç›®æ¨™åƒ¹æ ¼ï¼š

## é¢¨éšªè©•ä¼°
- å¸‚å ´é¢¨éšªï¼š
- è²¡å‹™é¢¨éšªï¼š
- æ³•è¦/æ”¿ç­–é¢¨éšªï¼š

## çµè«–
ï¼ˆç¸½çµæŠ•è³‡è§€é»èˆ‡é—œéµè¿½è¹¤æŒ‡æ¨™ï¼‰

ã€å¯ç”¨è³‡æ–™ã€‘
- æœå°‹äº‹å¯¦æ‘˜è¦ï¼š{search_ctx if search_ctx else 'æœªæä¾›'}
- æœ€æ–°å­£åº¦ EPSï¼š{metrics.get('latest_eps', 'æœªæä¾›')}
- ä¸Šå­£ EPSï¼š{metrics.get('prev_eps', 'æœªæä¾›')}
- è¿‘ 12 æœˆæœ€æ–°ç‡Ÿæ”¶ï¼ˆå„„å…ƒï¼‰ï¼š{metrics.get('latest_revenue', 'æœªæä¾›')}
- è¿‘ 12 æœˆæœ€èˆŠç‡Ÿæ”¶ï¼ˆå„„å…ƒï¼‰ï¼š{metrics.get('oldest_revenue', 'æœªæä¾›')}
- ä¼°ç®—ç‡Ÿæ”¶æˆé•·ç‡ï¼ˆæœ€æ–° vs æœ€èˆŠï¼‰ï¼š{metrics.get('revenue_growth', 'æœªæä¾›')}
""".strip()

# 1. æ ¸å¿ƒ AI å‘¼å«å·¥å…· (ä¿æŒç©©å®šï¼Œæœªæ›´å‹•)
def _call_nim_fundamental(cfg, prompt):
    llm_cfg = cfg.get("llm", {})
    url = "https://integrate.api.nvidia.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {llm_cfg.get('api_key')}", "Content-Type": "application/json"}
    payload = {
        "model": llm_cfg.get("model"),
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è­‰åˆ¸åˆ†æå¸«ã€‚è«‹å„ªå…ˆåƒè€ƒé€£ç¶²æœå°‹åˆ°çš„äº‹å¯¦ï¼Œçµåˆè²¡å‹™æ•¸æ“šçµ¦å‡ºå…·é«”çš„æŠ•è³‡è©•åƒ¹ï¼Œåš´ç¦è™›æ§‹å…¬å¸æ¥­å‹™ã€‚"},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.1
    }
    resp = requests.post(url, headers=headers, json=payload, timeout=60)
    return resp.json()["choices"][0]["message"]["content"]

def show_fundamental_analysis():
    st.markdown("### ğŸ’ åŸºæœ¬é¢æ•¸æ“šå…¨è¦½èˆ‡ AI è¨ºæ–·")
    cfg = database.load_config()
    conn = database.get_db_connection(cfg)
    universe = cfg.get("universe", [])
    stock_options = {f"{s['stock_id']} {s['name']}": s['stock_id'] for s in universe}
    
    selected_stock = st.selectbox("è«‹é¸æ“‡åˆ†ææ¨™çš„", list(stock_options.keys()))
    sid = stock_options[selected_stock]
    
    # çµ±ä¸€åŸºæº–æ—¥
    def_s = pd.to_datetime("today") - pd.Timedelta(days=60)
    def_e = pd.to_datetime("today")
    f_range = st.date_input("æ•¸æ“šè§€å¯ŸåŸºæº–æ—¥", value=[def_s, def_e])
    end_d = f_range[1] if len(f_range) == 2 else def_e

    st.divider()

    # --- 1. æ•¸æ“šæŠ“å–èˆ‡æ ¼å¼åŒ– ---
    
    # (1) æ¯æœˆç‡Ÿæ”¶ï¼šé™¤ä»¥ 1000 ä¸¦åŠ ä¸Šåƒåˆ†ä½ ","
    rev_query = f"SELECT date as 'æ—¥æœŸ', revenue FROM stock_month_revenue_monthly WHERE stock_id='{sid}' ORDER BY date DESC LIMIT 12"
    rev_df = pd.read_sql(rev_query, conn)
    if not rev_df.empty:
        # âœ… ä¿®æ­£é—œéµï¼šçµ±ä¸€æ¬„ä½åç¨±ç‚º 'ç‡Ÿæ”¶(å„„)'ï¼Œä¸¦åŠ ä¸Šåƒåˆ†ä½
        rev_df['ç‡Ÿæ”¶(å„„)'] = (rev_df['revenue'] / 100000000).apply(lambda x: f"{x:,.2f}")
        rev_df = rev_df[['æ—¥æœŸ', 'ç‡Ÿæ”¶(å„„)']]
    
    # (2+4) æ¯å­£ç²åˆ©èˆ‡ EPSï¼šå®‰å…¨è½‰ç½®è™•ç†
    profit_raw = pd.read_sql(f"SELECT date, type, value FROM stock_financial_statements WHERE stock_id='{sid}' AND type IN ('EPS', 'Net Profit') ORDER BY date DESC LIMIT 16", conn)
    if not profit_raw.empty:
        profit_df = profit_raw.pivot(index='date', columns='type', values='value').reset_index()
        # å®‰å…¨é‡å‘½å
        rename_map = {'date': 'å­£åº¦', 'EPS': 'EPS', 'Net Profit': 'æ¯å­£ç²åˆ©'}
        profit_df = profit_df.rename(columns={k: v for k, v in rename_map.items() if k in profit_df.columns})
        # åŠ ä¸Šåƒåˆ†ä½ (æ¯å­£ç²åˆ©)
        if 'æ¯å­£ç²åˆ©' in profit_df.columns:
            profit_df['æ¯å­£ç²åˆ©'] = profit_df['æ¯å­£ç²åˆ©'].apply(lambda x: f"{x:,.0f}" if pd.notnull(x) else "N/A")
    else:
        profit_df = pd.DataFrame()

    # (3+5) æœ¬ç›Šæ¯”èˆ‡æ®–åˆ©ç‡
    val_query = f"SELECT date as 'æ—¥æœŸ', PER as 'æœ¬ç›Šæ¯”', dividend_yield as 'æ®–åˆ©ç‡%' FROM stock_per_pbr_daily WHERE stock_id='{sid}' AND date <= '{end_d}' ORDER BY date DESC LIMIT 10"
    valuation_df = pd.read_sql(val_query, conn)

    # (6+7) ç¾é‡‘è‚¡åˆ©èˆ‡è‚¡æ¯åˆ†é…
    div_query = f"SELECT year as 'å¹´ä»½', CashEarningsDistribution as 'ç¾é‡‘è‚¡åˆ©', StockEarningsDistribution as 'è‚¡ç¥¨è‚¡åˆ©' FROM stock_dividend WHERE stock_id='{sid}' ORDER BY year DESC LIMIT 5"
    div_df = pd.read_sql(div_query, conn)

    # --- 2. è¡¨æ ¼åŒ–é¡¯ç¤ºåˆ†é  ---
    tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ ç‡Ÿæ”¶èˆ‡ç²åˆ©è©³æƒ…", "ğŸ’° è‚¡åˆ©èˆ‡ä¼°å€¼çœ‹æ¿", "ğŸ” AI è¯ç¶²è¶¨å‹¢å ±å‘Š"])

    with tab1:
        st.write("#### 1. æ¯æœˆç‡Ÿæ”¶ (å–®ä½ï¼šç™¾è¬å…ƒ)")
        st.dataframe(rev_df, use_container_width=True, hide_index=True)
        
        st.write("#### 2 & 4. æ¯å­£ç²åˆ©èˆ‡ EPS æ­·ç¨‹")
        if not profit_df.empty:
            # ç¢ºä¿åƒ…é¡¯ç¤ºç¾æœ‰æ¬„ä½
            cols_to_show = [c for c in ['å­£åº¦', 'æ¯å­£ç²åˆ©', 'EPS'] if c in profit_df.columns]
            st.dataframe(profit_df[cols_to_show], use_container_width=True, hide_index=True)
        else:
            st.info("å°šç„¡ç²åˆ©æ•¸æ“šã€‚")

    with tab2:
        st.write("#### 3 & 5. æœ¬ç›Šæ¯”èˆ‡æ®–åˆ©ç‡è®Šå‹•")
        st.dataframe(valuation_df, use_container_width=True, hide_index=True)
        
        st.write("#### 6 & 7. æ­·å¹´è‚¡åˆ©åˆ†é… (ç¾é‡‘èˆ‡è‚¡ç¥¨)")
        if not div_df.empty:
            st.table(div_df)
        else:
            st.info("å°šç„¡è‚¡åˆ©æ­·å²æ•¸æ“šã€‚")

    with tab3:
        # âœ… ä¿ç•™è¯ç¶²æœå°‹é‚è¼¯
        if st.button(f"ğŸš€ å•Ÿå‹• {selected_stock} è¯ç¶²äº‹å¯¦åˆ†æ", use_container_width=True):
            with st.spinner("æ­£åœ¨æœå°‹æœ€æ–°ç”¢æ¥­åœ°ä½èˆ‡å¸‚å ´æ–°è..."):
                search_ctx = ""
                try:
                    with DDGS() as ddgs:
                        for r in ddgs.text(f"{selected_stock} æ ¸å¿ƒç”¢å“ ç”¢æ¥­åœ°ä½ æœ€æ–°æ–°è", max_results=5):
                            search_ctx += f"\n- {r['title']}: {r['body']}"
                except: pass
                
                # ç²å– AI åƒè€ƒæ•¸æ“š
                latest_eps = profit_df['EPS'].iloc[0] if ('EPS' in profit_df.columns and not profit_df.empty) else "æœªæä¾›"
                prev_eps = profit_df['EPS'].iloc[1] if ('EPS' in profit_df.columns and len(profit_df) > 1) else "æœªæä¾›"

                latest_revenue = rev_df['ç‡Ÿæ”¶(å„„)'].iloc[0] if not rev_df.empty else "æœªæä¾›"
                oldest_revenue = rev_df['ç‡Ÿæ”¶(å„„)'].iloc[-1] if not rev_df.empty else "æœªæä¾›"

                revenue_growth = "æœªæä¾›"
                if not rev_df.empty and len(rev_df) > 1:
                    rev_num = pd.to_numeric(rev_df['ç‡Ÿæ”¶(å„„)'].str.replace(',', ''), errors='coerce')
                    latest_rev_num = rev_num.iloc[0]
                    oldest_rev_num = rev_num.iloc[-1]
                    if pd.notnull(latest_rev_num) and pd.notnull(oldest_rev_num) and oldest_rev_num != 0:
                        revenue_growth = f"{((latest_rev_num - oldest_rev_num) / oldest_rev_num) * 100:.2f}%"

                metrics = {
                    "latest_eps": latest_eps,
                    "prev_eps": prev_eps,
                    "latest_revenue": latest_revenue,
                    "oldest_revenue": oldest_revenue,
                    "revenue_growth": revenue_growth
                }

                prompt = _build_fundamental_prompt(selected_stock, sid, search_ctx, metrics)
                st.markdown(_call_nim_fundamental(cfg, prompt))

    conn.close()
