import streamlit as st
import pandas as pd
import database
import requests
from duckduckgo_search import DDGS



def _normalize_secret(value):
    """å»é™¤å¸¸è¦‹è²¼ä¸Šæ±¡æŸ“ï¼ˆç©ºç™½/æ›è¡Œ/BOMï¼‰ã€‚"""
    if value is None:
        return ""
    return str(value).replace("ï»¿", "").strip()


def _google_error_hint(err_msg):
    """å°‡ Google API å¸¸è¦‹éŒ¯èª¤è½‰æˆå¯æ“ä½œå»ºè­°ã€‚"""
    msg = (err_msg or "").lower()
    if "api key not valid" in msg or "invalid" in msg:
        return "è«‹ç¢ºèªï¼š1) API key å±¬æ–¼åŒä¸€å€‹ GCP å°ˆæ¡ˆï¼›2) å·²å•Ÿç”¨ Custom Search JSON APIï¼›3) key æ²’æœ‰è¢« HTTP referrer/IP é™åˆ¶æ“‹ä½æ­¤åŸ·è¡Œç’°å¢ƒã€‚"
    if "referer" in msg or "ip" in msg or "not allowed" in msg:
        return "æ­¤é‡‘é‘°é™åˆ¶ä¸ç¬¦ï¼ˆHTTP referrer/IPï¼‰ã€‚è‹¥åœ¨æœ¬æ©Ÿ Python å¾Œç«¯å‘¼å«ï¼Œè«‹ç§»é™¤ referrer é™åˆ¶æˆ–æ”¹ç”¨å…è¨±è©²ä¾†æºçš„é‡‘é‘°ã€‚"
    if "quota" in msg or "rate limit" in msg:
        return "å·²é”é…é¡ä¸Šé™ï¼Œè«‹æª¢æŸ¥ GCP Quotas/è¨ˆè²»è¨­å®šã€‚"
    if "access not configured" in msg or "has not been used" in msg:
        return "å°šæœªå•Ÿç”¨ Custom Search JSON APIï¼Œè«‹åˆ° Google Cloud Console å•Ÿç”¨å¾Œå†è©¦ã€‚"
    return "è«‹æª¢æŸ¥ API key æ˜¯å¦æ­£ç¢ºã€Custom Search JSON API æ˜¯å¦å•Ÿç”¨ã€ä»¥åŠ key é™åˆ¶æ˜¯å¦å…è¨±ç›®å‰åŸ·è¡Œç’°å¢ƒã€‚"



def _mask_secret(value, keep=4):
    """é®ç½©æ•æ„Ÿè³‡è¨Šï¼Œé¿å…å®Œæ•´é‡‘é‘°å¤–éœ²ã€‚"""
    val = _normalize_secret(value)
    if not val:
        return "(æœªè¨­å®š)"
    if len(val) <= keep:
        return "*" * len(val)
    return f"{'*' * (len(val) - keep)}{val[-keep:]}"


def _google_connectivity_check(cfg):
    """å¿«é€Ÿæª¢æŸ¥ Google CSE API æ˜¯å¦å¯ç”±ç›®å‰ç’°å¢ƒæˆåŠŸå‘¼å«ã€‚"""
    search_cfg = cfg.get("search", {})
    api_key = _normalize_secret(search_cfg.get("google_api_key"))
    cse_id = _normalize_secret(search_cfg.get("google_cse_id"))
    if not api_key or not cse_id:
        return False, "Google æª¢æŸ¥å¤±æ•—ï¼šgoogle_api_key æˆ– google_cse_id æœªè¨­å®šã€‚"

    try:
        resp = requests.get(
            "https://www.googleapis.com/customsearch/v1",
            params={"key": api_key, "cx": cse_id, "q": "å°è‚¡", "num": 1, "hl": "zh-TW"},
            timeout=20,
        )
        data = resp.json()
        if resp.status_code >= 400:
            err_msg = data.get("error", {}).get("message", f"HTTP {resp.status_code}") if isinstance(data, dict) else f"HTTP {resp.status_code}"
            return False, f"Google é€£ç·šæª¢æŸ¥å¤±æ•—ï¼š{err_msg}ï½œå»ºè­°ï¼š{_google_error_hint(err_msg)}"

        total = data.get("searchInformation", {}).get("totalResults", "?") if isinstance(data, dict) else "?"
        return True, f"Google é€£ç·šæª¢æŸ¥æˆåŠŸï¼šAPI å¯ç”¨ï¼ˆtotalResults={total}ï¼‰ã€‚"
    except Exception as exc:
        return False, f"Google é€£ç·šæª¢æŸ¥ä¾‹å¤–ï¼š{str(exc)}"

PUTER_JS_SNIPPET = """<script src="https://js.puter.com/v2/"></script>
<script>
async function runPuterDemo() {
  try {
    const response = await puter.ai.chat(
      "é‡å­é‹ç®—çš„æœ€æ–°é€²å±•æ˜¯ä»€éº¼ï¼Ÿ",
      { model: "perplexity/sonar" }
    );
    console.log(response);
  } catch (err) {
    console.error("Puter å‘¼å«å¤±æ•—:", err);
  }
}
runPuterDemo();
</script>
"""


def _google_search(query, cfg, max_results=5):
    """é€é Google Custom Search å–å¾—æœå°‹æ‘˜è¦ã€‚"""
    search_cfg = cfg.get("search", {})
    api_key = _normalize_secret(search_cfg.get("google_api_key"))
    cse_id = _normalize_secret(search_cfg.get("google_cse_id"))
    if not api_key or not cse_id:
        return [], "Google æœªè¨­å®š google_api_key æˆ– google_cse_idã€‚"

    try:
        resp = requests.get(
            "https://www.googleapis.com/customsearch/v1",
            params={
                "key": api_key,
                "cx": cse_id,
                "q": query,
                "num": min(max_results, 10),
                "hl": "zh-TW"
            },
            timeout=20,
        )
        data = resp.json()
        if resp.status_code >= 400:
            err_msg = data.get("error", {}).get("message", f"HTTP {resp.status_code}") if isinstance(data, dict) else f"HTTP {resp.status_code}"
            hint = _google_error_hint(err_msg)
            return [], f"Google æœå°‹å¤±æ•—ï¼š{err_msg}ï½œå»ºè­°ï¼š{hint}"

        items = data.get("items", []) if isinstance(data, dict) else []
        records = [
            {
                "source": "Google",
                "title": i.get("title", ""),
                "snippet": i.get("snippet", ""),
                "url": i.get("link", ""),
            }
            for i in items
        ]
        if not records:
            return [], "Google å·²é€£ç·šï¼Œä½†æ­¤æŸ¥è©¢ç„¡çµæœã€‚"
        return records, None
    except Exception as exc:
        return [], f"Google æœå°‹ä¾‹å¤–ï¼š{str(exc)}"


def _perplexity_search(query, cfg):
    """é€é Perplexity API å–å¾—å¤–éƒ¨è³‡è¨Šæ‘˜è¦ã€‚"""
    search_cfg = cfg.get("search", {})
    api_key = _normalize_secret(search_cfg.get("perplexity_api_key"))
    model = search_cfg.get("perplexity_model", "sonar")
    if not api_key:
        return [], "Perplexity æœªè¨­å®š perplexity_api_keyã€‚"

    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {
        "model": model,
        "messages": [
            {
                "role": "system",
                "content": "ä½ æ˜¯ç ”ç©¶åŠ©ç†ï¼Œè«‹æ ¹æ“šæœ€æ–°ç¶²è·¯å…¬é–‹è³‡è¨Šæ•´ç†é‡é»ï¼Œä¸¦é™„ä¸Šä¾†æºç¶²å€ã€‚",
            },
            {
                "role": "user",
                "content": f"è«‹é‡å°ä»¥ä¸‹ä¸»é¡Œæ•´ç† 5 é»é‡é»ï¼Œæ ¼å¼ç‚ºä¸€è¡Œä¸€é»ï¼Œä¸”æ¯é»é™„ä¾†æºç¶²å€ï¼š{query}",
            },
        ],
        "temperature": 0.0,
    }

    try:
        resp = requests.post(
            "https://api.perplexity.ai/chat/completions",
            headers=headers,
            json=payload,
            timeout=30,
        )
        data = resp.json()
        if resp.status_code >= 400:
            err_msg = data.get("error", {}).get("message", f"HTTP {resp.status_code}") if isinstance(data, dict) else f"HTTP {resp.status_code}"
            return [], f"Perplexity æœå°‹å¤±æ•—ï¼š{err_msg}"

        content = data.get("choices", [{}])[0].get("message", {}).get("content", "") if isinstance(data, dict) else ""
        if not content:
            return [], "Perplexity å·²é€£ç·šï¼Œä½†ç„¡å›å‚³å…§å®¹ã€‚"
        return [{"source": "Perplexity", "title": "æ‘˜è¦", "snippet": content, "url": ""}], None
    except Exception as exc:
        return [], f"Perplexity æœå°‹ä¾‹å¤–ï¼š{str(exc)}"


def _ddg_search(query, max_results=5, source="DuckDuckGo"):
    try:
        with DDGS() as ddgs:
            results = []
            for r in ddgs.text(query, max_results=max_results):
                results.append(
                    {
                        "source": source,
                        "title": r.get("title", ""),
                        "snippet": r.get("body", ""),
                        "url": r.get("href", ""),
                    }
                )
            if not results:
                return [], f"{source} æŸ¥è©¢ç„¡çµæœã€‚"
            return results, None
    except Exception as exc:
        return [], f"{source} æœå°‹ä¾‹å¤–ï¼š{str(exc)}"


def _build_external_context(stock_name, sid, cfg):
    """è’é›†å¤–éƒ¨è³‡è¨Šï¼ˆå¯é…ç½®ä»˜è²»/å…è²»ä¾†æº + ç¤¾ç¾¤ç¶²ç«™æœå°‹ï¼‰ã€‚"""
    base_query = f"{stock_name} {sid} æ ¸å¿ƒç”¢å“ ç”¢æ¥­åœ°ä½ æœ€æ–°æ–°è"
    search_cfg = cfg.get("search", {})
    preferred_provider = str(search_cfg.get("provider", "ddg")).lower().strip()

    records = []
    warnings = []

    if preferred_provider == "google":
        google_records, google_warn = _google_search(base_query, cfg, max_results=6)
        records.extend(google_records)
        if google_warn:
            warnings.append(google_warn)
    elif preferred_provider == "perplexity":
        pplx_records, pplx_warn = _perplexity_search(base_query, cfg)
        records.extend(pplx_records)
        if pplx_warn:
            warnings.append(pplx_warn)

    ddg_records, ddg_warn = _ddg_search(base_query, max_results=5, source="DuckDuckGo")
    records.extend(ddg_records)
    if ddg_warn:
        warnings.append(ddg_warn)

    # ç¤¾ç¾¤/è¼¿æƒ…ï¼ˆä»¥å…¬é–‹å¯ç´¢å¼•é é¢ç‚ºä¸»ï¼Œéç™»å…¥è³‡æ–™ï¼‰
    social_queries = [
        (f"site:x.com OR site:twitter.com {stock_name} {sid}", "X/Twitter"),
        (f"site:facebook.com {stock_name} {sid}", "Facebook"),
        (f"site:instagram.com {stock_name} {sid}", "Instagram"),
    ]
    for query, source in social_queries:
        social_records, social_warn = _ddg_search(query, max_results=3, source=source)
        records.extend(social_records)
        if social_warn:
            warnings.append(social_warn)

    if not records:
        warnings.insert(0, "ç›®å‰æœªå–å¾—å¤–éƒ¨ä¾†æºã€‚è«‹å…ˆæª¢æŸ¥ä¸‹æ–¹å„ä¾†æºè¨ºæ–·è¨Šæ¯ã€‚")
        return "", warnings

    source_counts = {}
    for rec in records:
        src = rec.get("source", "ä¾†æº")
        source_counts[src] = source_counts.get(src, 0) + 1
    summary = "ã€".join([f"{k}:{v}" for k, v in source_counts.items()])
    warnings.insert(0, f"å¤–éƒ¨ä¾†æºæŠ“å–æˆåŠŸï¼ˆ{summary}ï¼‰ã€‚")

    lines = []
    for rec in records[:20]:
        url = rec.get("url", "")
        url_text = f"ï¼ˆ{url}ï¼‰" if url else ""
        lines.append(f"- [{rec.get('source', 'ä¾†æº')}] {rec.get('title', '')}: {rec.get('snippet', '')} {url_text}")
    return "\n".join(lines), warnings


def _fmt_metric(value, fallback="æœªæä¾›"):
    if value is None or value == "":
        return fallback
    return str(value)


def _to_float(value):
    if value is None:
        return None
    text = str(value).replace(",", "").replace("%", "").strip()
    if text in {"", "æœªæä¾›", "N/A", "nan"}:
        return None
    try:
        return float(text)
    except (TypeError, ValueError):
        return None


def _free_score_label(score):
    if score >= 2:
        return "åå¤š"
    if score <= -2:
        return "åä¿å®ˆ"
    return "ä¸­æ€§"


def _latest_metric_value(financial_df, metric_names):
    """å¾è²¡å ±æ˜ç´°ä¸­å–å‡ºæŒ‡å®šæŒ‡æ¨™çš„æœ€æ–°å€¼ã€‚"""
    if financial_df.empty:
        return None

    norm_names = {str(n).strip().lower() for n in metric_names}
    matched = financial_df[financial_df["type"].astype(str).str.strip().str.lower().isin(norm_names)]
    if matched.empty:
        return None
    return matched.iloc[0]["value"]


def _fmt_percent(value):
    val = _to_float(value)
    if val is None:
        return "æœªæä¾›"
    return f"{val:.2f}%"


def _compute_data_quality(metrics):
    required = [
        "latest_eps",
        "prev_eps",
        "latest_revenue",
        "oldest_revenue",
        "revenue_growth",
        "roe",
        "roa",
        "gross_margin",
        "operating_cf",
    ]
    available = sum(1 for key in required if _to_float(metrics.get(key)) is not None)
    ratio = available / len(required)

    if ratio >= 0.8:
        return "é«˜", ratio
    if ratio >= 0.5:
        return "ä¸­", ratio
    return "ä½", ratio


def _build_free_fundamental_report(stock_name, sid, search_ctx, metrics):
    latest_eps = _to_float(metrics.get("latest_eps"))
    prev_eps = _to_float(metrics.get("prev_eps"))
    revenue_growth = _to_float(metrics.get("revenue_growth"))

    eps_trend = "è³‡æ–™ä¸è¶³"
    if latest_eps is not None and prev_eps is not None:
        eps_trend = "æˆé•·" if latest_eps > prev_eps else ("ä¸‹æ»‘" if latest_eps < prev_eps else "æŒå¹³")

    score = 0
    if latest_eps is not None:
        score += 1 if latest_eps > 0 else -1
    if revenue_growth is not None:
        score += 1 if revenue_growth > 0 else -1
    if latest_eps is not None and prev_eps is not None and latest_eps > prev_eps:
        score += 1

    risk_note = "å¸‚å ´æ™¯æ°£å¾ªç’°èˆ‡ç”¢æ¥­ç«¶çˆ­å¯èƒ½å½±éŸ¿ç‡Ÿæ”¶èˆ‡ç²åˆ©ã€‚"
    if latest_eps is not None and latest_eps < 0:
        risk_note = "ç›®å‰ EPS ç‚ºè² ï¼Œéœ€å„ªå…ˆé—œæ³¨è™§ææ”¶æ–‚èˆ‡ç¾é‡‘æµå“è³ªã€‚"
    elif revenue_growth is not None and revenue_growth < 0:
        risk_note = "è¿‘æœŸç‡Ÿæ”¶æˆé•·ç‡ç‚ºè² ï¼Œéœ€ç•™æ„éœ€æ±‚æ”¾ç·©æˆ–ç”¢å“çµ„åˆè®ŠåŒ–ã€‚"

    ext_note = "æœªå–å¾—å¤–éƒ¨æ–°èæ‘˜è¦ã€‚"
    if search_ctx:
        ext_note = "å·²ç´å…¥ DuckDuckGo èˆ‡ç¤¾ç¾¤å…¬é–‹é é¢æ‘˜è¦ï¼ˆå…è²»ä¾†æºï¼‰ã€‚"

    data_quality_level, data_quality_ratio = _compute_data_quality(metrics)

    return f"""
## å…¬å¸ç°¡ä»‹
{stock_name}ï¼ˆ{sid}ï¼‰ç‚ºå°è‚¡ä¸Šå¸‚æ«ƒå…¬å¸ï¼Œæœ¬å ±å‘Šæ¡ç”¨å…§éƒ¨è³‡æ–™åº«è²¡å ±æ¬„ä½èˆ‡å…è²»å¤–éƒ¨æœå°‹æ‘˜è¦é€²è¡Œæ•´ç†ã€‚

## è²¡å‹™åˆ†æ
ç›®å‰è§€å¯Ÿåˆ° EPS è¶¨å‹¢ç‚ºã€Œ{eps_trend}ã€ï¼Œæ•´é«”è²¡å‹™å‹•èƒ½åˆ¤è®€ç‚ºã€Œ{_free_score_label(score)}ã€ã€‚
{ext_note}

### è²¡å‹™æŒ‡æ¨™
- EPSï¼š{_fmt_metric(metrics.get('latest_eps'))}
- ROEï¼ˆè‚¡æ±æ¬Šç›Šå ±é…¬ç‡ï¼‰ï¼š{_fmt_percent(metrics.get('roe'))}
- ROAï¼ˆè³‡ç”¢å ±é…¬ç‡ï¼‰ï¼š{_fmt_percent(metrics.get('roa'))}
- ç‡Ÿæ”¶æˆé•·ç‡ï¼š{_fmt_metric(metrics.get('revenue_growth'))}
- æ¯›åˆ©ç‡ï¼š{_fmt_percent(metrics.get('gross_margin'))}

## ç‡Ÿæ”¶åˆ†æ
è¿‘ 12 æœˆç‡Ÿæ”¶ç”± { _fmt_metric(metrics.get('oldest_revenue')) } å„„è®ŠåŒ–è‡³ { _fmt_metric(metrics.get('latest_revenue')) } å„„ï¼Œæˆé•·ç‡ç‚º { _fmt_metric(metrics.get('revenue_growth')) }ã€‚
è‹¥æˆé•·ç‡è½‰å¼±ï¼Œé€šå¸¸ä»£è¡¨çµ‚ç«¯éœ€æ±‚ã€ç”¢å“åƒ¹æ ¼æˆ–å‡ºè²¨ç¯€å¥æ‰¿å£“ã€‚

## æ¯›åˆ©ç‡åˆ†æ
ç›®å‰è³‡æ–™åº«æœªæä¾›å¯ç›´æ¥è¨ˆç®—çš„æœ€æ–°æ¯›åˆ©ç‡æ¬„ä½ï¼Œå»ºè­°å¾ŒçºŒè£œé½Šå­£å ±æ¯›åˆ©ç‡ä»¥æå‡åˆ¤è®€ç²¾åº¦ã€‚

## ç¾é‡‘æµé‡åˆ†æ
ç‡Ÿæ¥­ç¾é‡‘æµï¼ˆOperating Cash Flowï¼‰ï¼š{_fmt_metric(metrics.get('operating_cf'))}ã€‚
è‹¥ç‡Ÿæ”¶èˆ‡ç²åˆ©æˆé•·ä½†ç¾é‡‘æµæœªåŒæ­¥æ”¹å–„ï¼Œéœ€ç•™æ„æ‡‰æ”¶å¸³æ¬¾ã€åº«å­˜èˆ‡è³‡æœ¬æ”¯å‡ºå£“åŠ›ã€‚

## æŠ•è³‡è©•åƒ¹
- çŸ­æœŸè©•åƒ¹ï¼š{_free_score_label(score)}ï¼ˆä»¥ç‡Ÿæ”¶èˆ‡ EPS æœ€æ–°è®ŠåŒ–ç‚ºä¸»ï¼‰
- ä¸­æœŸè©•åƒ¹ï¼šä¸­æ€§ååŸºæœ¬é¢é©—è­‰ï¼ˆéœ€è¿½è¹¤é€£çºŒ 2~3 å­£ï¼‰
- é•·æœŸè©•åƒ¹ï¼šå–æ±ºæ–¼ç”¢å“ç«¶çˆ­åŠ›ã€è³‡æœ¬æ”¯å‡ºæ•ˆç‡èˆ‡æ™¯æ°£å¾ªç’°ä½ç½®
- ç›®æ¨™åƒ¹æ ¼ï¼šè³‡æ–™ä¸è¶³ï¼ˆå…è²»ç‰ˆä¸ç”¢ç”Ÿç›®æ¨™åƒ¹ï¼‰

## é¢¨éšªè©•ä¼°
- å¸‚å ´é¢¨éšªï¼šå—ç¸½é«”æ™¯æ°£ã€åˆ©ç‡èˆ‡è³‡é‡‘é¢å½±éŸ¿
- è²¡å‹™é¢¨éšªï¼š{risk_note}
- æ³•è¦/æ”¿ç­–é¢¨éšªï¼šéœ€ç•™æ„ç”¢æ¥­æ”¿ç­–ã€å‡ºå£ç®¡åˆ¶èˆ‡æœƒè¨ˆæº–å‰‡è®Šå‹•

## çµè«–
æœ¬æ¬¡ç‚ºã€Œå…è²»ç‰ˆ AI åŸºæœ¬é¢åˆ†æã€ï¼Œä»¥å¯é©—è­‰æ•¸æ“šåšè¦å‰‡åŒ–æ‘˜è¦ï¼›è‹¥å•Ÿç”¨ LLM å¯å†é€²ä¸€æ­¥åšè„ˆçµ¡æ•´åˆã€‚
ç›®å‰è³‡æ–™å®Œæ•´åº¦è©•ä¼°ï¼š{data_quality_level}ï¼ˆ{data_quality_ratio:.0%}ï¼‰ã€‚
å»ºè­°å¾ŒçºŒæŒçºŒè¿½è¹¤ï¼šEPS é€£çºŒæ€§ã€ç‡Ÿæ”¶å¹´å¢ç‡è½‰æŠ˜ã€ç¾é‡‘æµå“è³ªï¼Œä»¥åŠé‡å¤§æ–°èäº‹ä»¶å°è¨‚å–®èˆ‡æ¯›åˆ©ç‡çš„å½±éŸ¿ã€‚
""".strip()


def _build_fundamental_prompt(stock_name, sid, search_ctx, metrics):
    """å»ºç«‹å›ºå®šç« ç¯€æ ¼å¼çš„åŸºæœ¬é¢åˆ†æ Promptã€‚"""
    return f"""
è«‹ä½ æ‰®æ¼”å°è‚¡è³‡æ·±åŸºæœ¬é¢åˆ†æå¸«ï¼Œé‡å° {stock_name}ï¼ˆ{sid}ï¼‰æ’°å¯«å ±å‘Šã€‚

ã€é‡è¦è¦å‰‡ã€‘
1) åš´æ ¼ä½¿ç”¨ä»¥ä¸‹å›ºå®šæ ¼å¼èˆ‡æ¨™é¡Œé †åºï¼Œä¸è¦å¢æ¸›ç« ç¯€ã€‚
2) è‹¥è³‡æ–™ä¸è¶³ï¼Œè«‹æ˜ç¢ºå¯«ã€Œæœªæä¾›ã€æˆ–ã€Œè³‡æ–™ä¸è¶³ã€ï¼Œç¦æ­¢è™›æ§‹ã€‚
3) æ‰€æœ‰æ•¸å€¼ç›¡é‡å¼•ç”¨æˆ‘æä¾›çš„è³‡æ–™ï¼›è‹¥å¼•ç”¨æ–°èï¼Œåƒ…èƒ½ä½¿ç”¨ã€Œæœå°‹äº‹å¯¦æ‘˜è¦ã€ã€‚
4) ä»¥ç¹é«”ä¸­æ–‡è¼¸å‡ºã€‚

ã€å›ºå®šè¼¸å‡ºæ ¼å¼ã€‘
## å…¬å¸ç°¡ä»‹
ï¼ˆå…¬å¸å®šä½ã€æ ¸å¿ƒç”¢å“/æœå‹™ã€ä¸»è¦å¸‚å ´ï¼‰

## è²¡å‹™åˆ†æ
ï¼ˆæ•´é«”ç²åˆ©èƒ½åŠ›èˆ‡è¿‘æ³ï¼Œ2-4 å¥ï¼‰

### è²¡å‹™æŒ‡æ¨™
- EPSï¼š
- ROEï¼ˆè‚¡æ±æ¬Šç›Šå ±é…¬ç‡ï¼‰ï¼š
- ROAï¼ˆè³‡ç”¢å ±é…¬ç‡ï¼‰ï¼š
- ç‡Ÿæ”¶æˆé•·ç‡ï¼š
- æ¯›åˆ©ç‡ï¼š

## ç‡Ÿæ”¶åˆ†æ
ï¼ˆç‡Ÿæ”¶è¶¨å‹¢ã€å¯èƒ½é©…å‹•å› å­ï¼‰

## æ¯›åˆ©ç‡åˆ†æ
ï¼ˆæ¯›åˆ©ç‡æ°´æº–èˆ‡å¯èƒ½åŸå› ï¼›è‹¥ç„¡è³‡æ–™è«‹å¯«æœªæä¾›ï¼‰

## ç¾é‡‘æµé‡åˆ†æ
ï¼ˆç¾é‡‘æµé‡ç‹€æ³èˆ‡å“è³ªï¼›è‹¥ç„¡è³‡æ–™è«‹å¯«æœªæä¾›ï¼‰

## æŠ•è³‡è©•åƒ¹
- çŸ­æœŸè©•åƒ¹ï¼š
- ä¸­æœŸè©•åƒ¹ï¼š
- é•·æœŸè©•åƒ¹ï¼š
- ç›®æ¨™åƒ¹æ ¼ï¼š

## é¢¨éšªè©•ä¼°
- å¸‚å ´é¢¨éšªï¼š
- è²¡å‹™é¢¨éšªï¼š
- æ³•è¦/æ”¿ç­–é¢¨éšªï¼š

## çµè«–
ï¼ˆç¸½çµæŠ•è³‡è§€é»èˆ‡é—œéµè¿½è¹¤æŒ‡æ¨™ï¼‰

ã€å¯ç”¨è³‡æ–™ã€‘
- æœå°‹äº‹å¯¦æ‘˜è¦ï¼š{search_ctx if search_ctx else 'æœªæä¾›'}
- æœ€æ–°å­£åº¦ EPSï¼š{metrics.get('latest_eps', 'æœªæä¾›')}
- ä¸Šå­£ EPSï¼š{metrics.get('prev_eps', 'æœªæä¾›')}
- è¿‘ 12 æœˆæœ€æ–°ç‡Ÿæ”¶ï¼ˆå„„å…ƒï¼‰ï¼š{metrics.get('latest_revenue', 'æœªæä¾›')}
- è¿‘ 12 æœˆæœ€èˆŠç‡Ÿæ”¶ï¼ˆå„„å…ƒï¼‰ï¼š{metrics.get('oldest_revenue', 'æœªæä¾›')}
- ä¼°ç®—ç‡Ÿæ”¶æˆé•·ç‡ï¼ˆæœ€æ–° vs æœ€èˆŠï¼‰ï¼š{metrics.get('revenue_growth', 'æœªæä¾›')}
- ROEï¼š{metrics.get('roe', 'æœªæä¾›')}
- ROAï¼š{metrics.get('roa', 'æœªæä¾›')}
- æ¯›åˆ©ç‡ï¼š{metrics.get('gross_margin', 'æœªæä¾›')}
- ç‡Ÿæ¥­ç¾é‡‘æµï¼š{metrics.get('operating_cf', 'æœªæä¾›')}
""".strip()

# 1. æ ¸å¿ƒ AI å‘¼å«å·¥å…· (ä¿æŒç©©å®šï¼Œæœªæ›´å‹•)
def _call_nim_fundamental(cfg, prompt):
    llm_cfg = cfg.get("llm", {})
    api_key = _normalize_secret(llm_cfg.get("api_key"))
    model_name = llm_cfg.get("model") or "meta/llama-3.1-70b-instruct"
    if not api_key:
        raise ValueError("llm.api_key æœªè¨­å®šã€‚")

    url = "https://integrate.api.nvidia.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {
        "model": model_name,
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è­‰åˆ¸åˆ†æå¸«ã€‚è«‹å„ªå…ˆåƒè€ƒé€£ç¶²æœå°‹åˆ°çš„äº‹å¯¦ï¼Œçµåˆè²¡å‹™æ•¸æ“šçµ¦å‡ºå…·é«”çš„æŠ•è³‡è©•åƒ¹ï¼Œåš´ç¦è™›æ§‹å…¬å¸æ¥­å‹™ã€‚"},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.1
    }
    resp = requests.post(url, headers=headers, json=payload, timeout=60)
    try:
        data = resp.json()
    except Exception:
        data = {}

    if resp.status_code >= 400:
        err_msg = data.get("error", {}).get("message") if isinstance(data, dict) else None
        raise RuntimeError(err_msg or f"NIM API å‘¼å«å¤±æ•—ï¼ˆHTTP {resp.status_code}ï¼‰ã€‚")

    content = data.get("choices", [{}])[0].get("message", {}).get("content", "") if isinstance(data, dict) else ""
    if not content:
        raise RuntimeError("NIM API æœªå›å‚³å¯ç”¨å…§å®¹ã€‚")
    return content

def show_fundamental_analysis():
    st.markdown("### ğŸ’ åŸºæœ¬é¢æ•¸æ“šå…¨è¦½èˆ‡ AI è¨ºæ–·")
    cfg = database.load_config()
    conn = database.get_db_connection(cfg)
    universe = cfg.get("universe", [])
    stock_options = {f"{s['stock_id']} {s['name']}": s['stock_id'] for s in universe}
    
    selected_stock = st.selectbox("è«‹é¸æ“‡åˆ†ææ¨™çš„", list(stock_options.keys()))
    sid = stock_options[selected_stock]
    
    # çµ±ä¸€åŸºæº–æ—¥
    def_s = pd.to_datetime("today") - pd.Timedelta(days=60)
    def_e = pd.to_datetime("today")
    f_range = st.date_input("æ•¸æ“šè§€å¯ŸåŸºæº–æ—¥", value=[def_s, def_e])
    end_d = f_range[1] if len(f_range) == 2 else def_e

    st.divider()

    # --- 1. æ•¸æ“šæŠ“å–èˆ‡æ ¼å¼åŒ– ---
    
    # (1) æ¯æœˆç‡Ÿæ”¶ï¼šé™¤ä»¥ 1000 ä¸¦åŠ ä¸Šåƒåˆ†ä½ ","
    rev_query = f"SELECT date as 'æ—¥æœŸ', revenue FROM stock_month_revenue_monthly WHERE stock_id='{sid}' ORDER BY date DESC LIMIT 12"
    rev_df = pd.read_sql(rev_query, conn)
    if not rev_df.empty:
        # âœ… ä¿®æ­£é—œéµï¼šçµ±ä¸€æ¬„ä½åç¨±ç‚º 'ç‡Ÿæ”¶(å„„)'ï¼Œä¸¦åŠ ä¸Šåƒåˆ†ä½
        rev_df['ç‡Ÿæ”¶(å„„)'] = (rev_df['revenue'] / 100000000).apply(lambda x: f"{x:,.2f}")
        rev_df = rev_df[['æ—¥æœŸ', 'ç‡Ÿæ”¶(å„„)']]
    
    # (2+4) æ¯å­£ç²åˆ©èˆ‡ EPSï¼šå®‰å…¨è½‰ç½®è™•ç†
    metric_candidates = [
        "EPS", "Net Profit", "ROE", "ROE(%)", "Return on Equity",
        "ROA", "ROA(%)", "Return on Assets",
        "Gross Margin", "Gross Margin(%)", "æ¯›åˆ©ç‡",
        "Operating Cash Flow", "ç‡Ÿæ¥­æ´»å‹•ä¹‹æ·¨ç¾é‡‘æµå…¥ï¼ˆæµå‡ºï¼‰", "ç‡Ÿæ¥­ç¾é‡‘æµ",
    ]
    metric_filter = ", ".join([f"'{m}'" for m in metric_candidates])
    profit_raw = pd.read_sql(
        f"SELECT date, type, value FROM stock_financial_statements WHERE stock_id='{sid}' AND type IN ({metric_filter}) ORDER BY date DESC LIMIT 200",
        conn,
    )
    if not profit_raw.empty:
        profit_df = profit_raw.pivot(index='date', columns='type', values='value').reset_index()
        # å®‰å…¨é‡å‘½å
        rename_map = {'date': 'å­£åº¦', 'EPS': 'EPS', 'Net Profit': 'æ¯å­£ç²åˆ©'}
        profit_df = profit_df.rename(columns={k: v for k, v in rename_map.items() if k in profit_df.columns})
        # åŠ ä¸Šåƒåˆ†ä½ (æ¯å­£ç²åˆ©)
        if 'æ¯å­£ç²åˆ©' in profit_df.columns:
            profit_df['æ¯å­£ç²åˆ©'] = profit_df['æ¯å­£ç²åˆ©'].apply(lambda x: f"{x:,.0f}" if pd.notnull(x) else "N/A")
    else:
        profit_df = pd.DataFrame()

    # (3+5) æœ¬ç›Šæ¯”èˆ‡æ®–åˆ©ç‡
    val_query = f"SELECT date as 'æ—¥æœŸ', PER as 'æœ¬ç›Šæ¯”', dividend_yield as 'æ®–åˆ©ç‡%' FROM stock_per_pbr_daily WHERE stock_id='{sid}' AND date <= '{end_d}' ORDER BY date DESC LIMIT 10"
    valuation_df = pd.read_sql(val_query, conn)

    # (6+7) ç¾é‡‘è‚¡åˆ©èˆ‡è‚¡æ¯åˆ†é…
    div_query = f"SELECT year as 'å¹´ä»½', CashEarningsDistribution as 'ç¾é‡‘è‚¡åˆ©', StockEarningsDistribution as 'è‚¡ç¥¨è‚¡åˆ©' FROM stock_dividend WHERE stock_id='{sid}' ORDER BY year DESC LIMIT 5"
    div_df = pd.read_sql(div_query, conn)

    # --- 2. è¡¨æ ¼åŒ–é¡¯ç¤ºåˆ†é  ---
    tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ ç‡Ÿæ”¶èˆ‡ç²åˆ©è©³æƒ…", "ğŸ’° è‚¡åˆ©èˆ‡ä¼°å€¼çœ‹æ¿", "ğŸ” AI è¯ç¶²è¶¨å‹¢å ±å‘Š"])

    with tab1:
        st.write("#### 1. æ¯æœˆç‡Ÿæ”¶ (å–®ä½ï¼šç™¾è¬å…ƒ)")
        st.dataframe(rev_df, use_container_width=True, hide_index=True)
        
        st.write("#### 2 & 4. æ¯å­£ç²åˆ©èˆ‡ EPS æ­·ç¨‹")
        if not profit_df.empty:
            # ç¢ºä¿åƒ…é¡¯ç¤ºç¾æœ‰æ¬„ä½
            cols_to_show = [c for c in ['å­£åº¦', 'æ¯å­£ç²åˆ©', 'EPS'] if c in profit_df.columns]
            st.dataframe(profit_df[cols_to_show], use_container_width=True, hide_index=True)
        else:
            st.info("å°šç„¡ç²åˆ©æ•¸æ“šã€‚")

    with tab2:
        st.write("#### 3 & 5. æœ¬ç›Šæ¯”èˆ‡æ®–åˆ©ç‡è®Šå‹•")
        st.dataframe(valuation_df, use_container_width=True, hide_index=True)
        
        st.write("#### 6 & 7. æ­·å¹´è‚¡åˆ©åˆ†é… (ç¾é‡‘èˆ‡è‚¡ç¥¨)")
        if not div_df.empty:
            st.table(div_df)
        else:
            st.info("å°šç„¡è‚¡åˆ©æ­·å²æ•¸æ“šã€‚")

    with tab3:
        llm_cfg = cfg.get("llm", {})
        llm_available = bool(_normalize_secret(llm_cfg.get("api_key")))

        use_llm = st.toggle(
            "å•Ÿç”¨ LLM å¼·åŒ–åˆ†æï¼ˆå¯é¸ï¼‰",
            value=llm_available,
            help="è‹¥å·²è¨­å®š llm.api_keyï¼Œå»ºè­°é–‹å•Ÿï¼›æœªå•Ÿç”¨æ™‚ç³»çµ±å°‡ä½¿ç”¨å…è²»è¦å‰‡åŒ–æ‘˜è¦ã€‚",
        )
        model_name = st.text_input(
            "LLM æ¨¡å‹ï¼ˆNVIDIA NIMï¼‰",
            value=llm_cfg.get("model") or "meta/llama-3.1-70b-instruct",
            disabled=not use_llm,
        )

        if use_llm and not llm_available:
            st.warning("ç›®å‰æœªè¨­å®š llm.api_keyï¼Œå°‡è‡ªå‹•å›é€€åˆ°å…è²»è¦å‰‡åŒ–å ±å‘Šã€‚")

        if llm_available:
            st.success(f"âœ… å·²åµæ¸¬åˆ° llm.api_keyï¼ˆ{_mask_secret(llm_cfg.get('api_key'))}ï¼‰ï¼Œå¯ç›´æ¥ä½¿ç”¨ {model_name} é€²è¡Œå¼·åŒ–åˆ†æã€‚")
        st.info("ğŸ’¡ æ”¹å–„å»ºè­°ï¼šè‹¥è¦æé«˜åŸºæœ¬é¢å“è³ªï¼Œè«‹è£œé½Š ROE/ROA/æ¯›åˆ©ç‡/ç¾é‡‘æµæ¬„ä½ï¼Œä¸¦æ­é… LLM åšäº¤å‰åˆ¤è®€ã€‚")

        run_btn_label = "ğŸš€ å•Ÿå‹• AI åŸºæœ¬é¢åˆ†æï¼ˆLLM å¼·åŒ–ï¼‰" if use_llm else "ğŸš€ å•Ÿå‹• AI åŸºæœ¬é¢åˆ†æï¼ˆå…è²»è¦å‰‡åŒ–ï¼‰"
        # âœ… ä¿ç•™è¯ç¶²æœå°‹é‚è¼¯
        if st.button(run_btn_label, use_container_width=True):
            with st.spinner("æ­£åœ¨æœå°‹æœ€æ–°ç”¢æ¥­åœ°ä½èˆ‡å¸‚å ´æ–°è..."):
                search_ctx, search_warnings = _build_external_context(selected_stock, sid, cfg)
                if search_warnings:
                    for w in search_warnings:
                        if w.startswith("å¤–éƒ¨ä¾†æºæŠ“å–æˆåŠŸ"):
                            st.success(w)
                        else:
                            st.warning(w)
                
                # ç²å– AI åƒè€ƒæ•¸æ“š
                latest_eps = profit_df['EPS'].iloc[0] if ('EPS' in profit_df.columns and not profit_df.empty) else "æœªæä¾›"
                prev_eps = profit_df['EPS'].iloc[1] if ('EPS' in profit_df.columns and len(profit_df) > 1) else "æœªæä¾›"

                latest_revenue = rev_df['ç‡Ÿæ”¶(å„„)'].iloc[0] if not rev_df.empty else "æœªæä¾›"
                oldest_revenue = rev_df['ç‡Ÿæ”¶(å„„)'].iloc[-1] if not rev_df.empty else "æœªæä¾›"

                revenue_growth = "æœªæä¾›"
                if not rev_df.empty and len(rev_df) > 1:
                    rev_num = pd.to_numeric(rev_df['ç‡Ÿæ”¶(å„„)'].str.replace(',', ''), errors='coerce')
                    latest_rev_num = rev_num.iloc[0]
                    oldest_rev_num = rev_num.iloc[-1]
                    if pd.notnull(latest_rev_num) and pd.notnull(oldest_rev_num) and oldest_rev_num != 0:
                        revenue_growth = f"{((latest_rev_num - oldest_rev_num) / oldest_rev_num) * 100:.2f}%"

                metrics = {
                    "latest_eps": latest_eps,
                    "prev_eps": prev_eps,
                    "latest_revenue": latest_revenue,
                    "oldest_revenue": oldest_revenue,
                    "revenue_growth": revenue_growth,
                    "roe": _latest_metric_value(profit_raw, ["ROE", "Return on Equity", "ROE(%)"]),
                    "roa": _latest_metric_value(profit_raw, ["ROA", "Return on Assets", "ROA(%)"]),
                    "gross_margin": _latest_metric_value(profit_raw, ["Gross Margin", "Gross Margin(%)", "æ¯›åˆ©ç‡"]),
                    "operating_cf": _latest_metric_value(profit_raw, ["Operating Cash Flow", "ç‡Ÿæ¥­æ´»å‹•ä¹‹æ·¨ç¾é‡‘æµå…¥ï¼ˆæµå‡ºï¼‰", "ç‡Ÿæ¥­ç¾é‡‘æµ"]),
                }

                if use_llm and llm_available:
                    cfg.setdefault("llm", {})["model"] = model_name
                    prompt = _build_fundamental_prompt(selected_stock, sid, search_ctx, metrics)
                    try:
                        ai_report = _call_nim_fundamental(cfg, prompt)
                        st.markdown(ai_report)
                    except Exception as exc:
                        st.error(f"LLM å‘¼å«å¤±æ•—ï¼Œæ”¹ç”¨å…è²»è¦å‰‡åŒ–å ±å‘Šï¼š{str(exc)}")
                        st.markdown(_build_free_fundamental_report(selected_stock, sid, search_ctx, metrics))
                else:
                    st.markdown(_build_free_fundamental_report(selected_stock, sid, search_ctx, metrics))

    conn.close()
